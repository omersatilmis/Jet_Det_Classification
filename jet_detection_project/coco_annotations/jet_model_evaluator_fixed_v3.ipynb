{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "86921da9",
      "metadata": {},
      "source": [
        "# Jet Detection – Model Evaluator (MMDetection)\n",
        "\n",
        "Bu notebook, **Cascade R-CNN** modelini (F16/F18/F22/F35) için:\n",
        "- COCO metrikleriyle (**mAP / AP50 / AP75 / AR@100**) değerlendirir\n",
        "- Sonuçları blok blok görselleştirir\n",
        "- (Opsiyonel) **Confusion Matrix + FP/FN** analizi yapar (daha yavaş)\n",
        "\n",
        "> Klasör düzeni (senin PC):\n",
        "- `C:\\Users\\omerf\\Desktop\\archive`\n",
        "- `C:\\Users\\omerf\\Desktop\\jet_detection_project`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "156ad73c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONFIG_PATH: configs/cascade_rcnn_r50_tiny.py\n",
            "CHECKPOINT_PATH: work_dirs\\cascade_rcnn_r50_tiny\\best_bbox_mAP_epoch_12.pth\n",
            "SPLIT: val\n"
          ]
        }
      ],
      "source": [
        "# Ayarlar (Notebook Evaluation)\n",
        "SPLIT = \"val\"  # \"val\" veya \"test\"\n",
        "\n",
        "# Opsiyonel analiz:\n",
        "RUN_CONFUSION = False\n",
        "IOU_THR = 0.5\n",
        "SCORE_THR = 0.3\n",
        "MAX_IMAGES = 200  # 0 => tümü (yavaş)\n",
        "\n",
        "print(\"SPLIT:\", SPLIT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b24c114",
      "metadata": {},
      "source": [
        "İmportların olduğu kısısm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "78a04f46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports OK\n"
          ]
        }
      ],
      "source": [
        "# ==== 1) Importlar ====\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mmengine.config import Config\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "from mmdet.utils import register_all_modules\n",
        "\n",
        "register_all_modules()\n",
        "print('Imports OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93959015",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ROOT : C:\\Users\\omerf\\Desktop\\jet_detection_project\n",
            "CONFIG_PATH  : C:\\Users\\omerf\\Desktop\\jet_detection_project\\codes\\configs\\cascade_rcnn_r50_tiny.py\n",
            "CKPT_PATH    : C:\\Users\\omerf\\Desktop\\jet_detection_project\\work_dirs\\cascade_rcnn_r50_tiny\\best_coco_bbox_mAP_epoch_12.pth\n",
            "CONFIG exists: True\n",
            "CKPT exists  : True\n",
            "DEVICE: cuda:0\n",
            "OUT_DIR: C:\\Users\\omerf\\Desktop\\jet_detection_project\\testing\\output_test\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# PROJE KÖKÜNÜ BUL (script + notebook uyumlu)\n",
        "# ---------------------------------------------------------\n",
        "def get_project_root() -> Path:\n",
        "    try:\n",
        "        start = Path(__file__).resolve()\n",
        "    except NameError:\n",
        "        # Notebook / interactive ortam\n",
        "        start = Path.cwd().resolve()\n",
        "\n",
        "    for p in [start] + list(start.parents):\n",
        "        # Senin proje yapın: <root>/codes + <root>/work_dirs\n",
        "        if (p / \"codes\").exists() and (p / \"work_dirs\").exists():\n",
        "            return p\n",
        "\n",
        "    raise RuntimeError(\"Proje kökü bulunamadı (codes + work_dirs aranıyor)\")\n",
        "\n",
        "PROJECT_ROOT = get_project_root()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# YOL VE CONFIG AYARLARI\n",
        "# ---------------------------------------------------------\n",
        "CONFIG_PATH = PROJECT_ROOT / \"codes\" / \"configs\" / \"cascade_rcnn_convnext_tiny.py\"\n",
        "CKPT_PATH   = PROJECT_ROOT / \"work_dirs\" / \"cascade_rcnn_r50_tiny\" / \"best_coco_bbox_mAP_epoch_21.pth\"\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# DEBUG / KONTROL\n",
        "# ---------------------------------------------------------\n",
        "print(\"PROJECT_ROOT :\", PROJECT_ROOT)\n",
        "print(\"CONFIG_PATH  :\", CONFIG_PATH)\n",
        "print(\"CKPT_PATH    :\", CKPT_PATH)\n",
        "print(\"CONFIG exists:\", CONFIG_PATH.exists())\n",
        "print(\"CKPT exists  :\", CKPT_PATH.exists())\n",
        "\n",
        "assert CONFIG_PATH.exists(), f\"Config yok: {CONFIG_PATH}\"\n",
        "assert CKPT_PATH.exists(), f\"Ckpt yok: {CKPT_PATH}\"\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# DİĞER AYARLAR\n",
        "# ---------------------------------------------------------\n",
        "DEVICE = \"cuda:0\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "OUT_DIR = PROJECT_ROOT / \"testing\" / \"output_test\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346b1f06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "work_dir: C:\\Users\\omerf\\Desktop\\jet_detection_project\\work_dirs\\cascade_rcnn_r50_tiny_nb_eval_val\n",
            "VAL ann : C:\\Users\\omerf\\Desktop\\jet_detection_project\\coco_annotations\\instances_validation.json exists: True\n",
            "TEST ann: C:\\Users\\omerf\\Desktop\\jet_detection_project\\coco_annotations\\instances_test.json exists: True\n",
            "COCO JSON'lar OK ✅\n"
          ]
        }
      ],
      "source": [
        "# Config yükle + (ÇÖZÜM-2) dataset ann_file path'lerini ABSOLUTE yap + work_dir ayarla + checkpoint yükle\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from mmengine.config import Config\n",
        "\n",
        "cfg = Config.fromfile(str(CONFIG_PATH))\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# ÇÖZÜM-2: Relative path yerine absolute path patch\n",
        "# ---------------------------------------------------------\n",
        "ANN_DIR = PROJECT_ROOT / \"coco_annotations\"\n",
        "VAL_ANN  = ANN_DIR / \"instances_validation.json\"\n",
        "TEST_ANN = ANN_DIR / \"instances_test.json\"\n",
        "\n",
        "assert VAL_ANN.exists(), f\"Val ann yok: {VAL_ANN}\"\n",
        "assert TEST_ANN.exists(), f\"Test ann yok: {TEST_ANN}\"\n",
        "\n",
        "# data_root'u proje kökü yap (bazı cfg'lerde join için kullanılıyor)\n",
        "cfg.data_root = str(PROJECT_ROOT) + os.sep\n",
        "\n",
        "# dataset ann_file patch\n",
        "if hasattr(cfg, \"val_dataloader\") and cfg.val_dataloader is not None:\n",
        "    cfg.val_dataloader.dataset.ann_file = str(VAL_ANN)\n",
        "\n",
        "if hasattr(cfg, \"test_dataloader\") and cfg.test_dataloader is not None:\n",
        "    cfg.test_dataloader.dataset.ann_file = str(TEST_ANN)\n",
        "\n",
        "# evaluator ann_file patch (CocoMetric buradan ann_file okuyor)\n",
        "if hasattr(cfg, \"val_evaluator\") and cfg.val_evaluator is not None:\n",
        "    # dict veya list olabilir\n",
        "    if isinstance(cfg.val_evaluator, dict):\n",
        "        cfg.val_evaluator.ann_file = str(VAL_ANN)\n",
        "    elif isinstance(cfg.val_evaluator, list):\n",
        "        for m in cfg.val_evaluator:\n",
        "            if isinstance(m, dict) and \"ann_file\" in m:\n",
        "                m[\"ann_file\"] = str(VAL_ANN)\n",
        "\n",
        "if hasattr(cfg, \"test_evaluator\") and cfg.test_evaluator is not None:\n",
        "    if isinstance(cfg.test_evaluator, dict):\n",
        "        cfg.test_evaluator.ann_file = str(TEST_ANN)\n",
        "    elif isinstance(cfg.test_evaluator, list):\n",
        "        for m in cfg.test_evaluator:\n",
        "            if isinstance(m, dict) and \"ann_file\" in m:\n",
        "                m[\"ann_file\"] = str(TEST_ANN)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# (Opsiyonel ama önerilir) Notebook'ta CWD'yi de proje köküne çek\n",
        "# ---------------------------------------------------------\n",
        "os.chdir(PROJECT_ROOT)\n",
        "print(\"CWD:\", Path.cwd())\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Checkpoint ve cihaz\n",
        "# ---------------------------------------------------------\n",
        "cfg.load_from = str(CKPT_PATH)\n",
        "cfg.device = DEVICE\n",
        "\n",
        "# notebook için ayrı work_dir (loglar karışmasın)\n",
        "cfg_stem = Path(CONFIG_PATH).stem\n",
        "eval_work_dir = PROJECT_ROOT / \"work_dirs\" / f\"{cfg_stem}_nb_eval_{SPLIT}\"\n",
        "eval_work_dir.mkdir(parents=True, exist_ok=True)\n",
        "cfg.work_dir = str(eval_work_dir)\n",
        "\n",
        "print(\"work_dir:\", cfg.work_dir)\n",
        "print(\"VAL ann :\", cfg.val_dataloader.dataset.ann_file)\n",
        "print(\"TEST ann:\", cfg.test_dataloader.dataset.ann_file)\n",
        "print(\"COCO JSON path patch OK ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d3ee8d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/22 13:12:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: win32\n",
            "    Python: 3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1752069318\n",
            "    GPU 0: NVIDIA GeForce RTX 2060\n",
            "    CUDA_HOME: None\n",
            "    GCC: n/a\n",
            "    PyTorch: 2.1.2+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - C++ Version: 199711\n",
            "  - MSVC 192930151\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 2019\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.5.4\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.2+cu118\n",
            "    OpenCV: 4.11.0\n",
            "    MMEngine: 0.10.4\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'spawn', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1752069318\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/22 13:12:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_root = 'coco_annotations/'\n",
            "classes = (\n",
            "    'F16',\n",
            "    'F18',\n",
            "    'F22',\n",
            "    'F35',\n",
            ")\n",
            "dataset_type = 'CocoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=1, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=50, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='DetVisualizationHook'))\n",
            "default_scope = 'mmdet'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='spawn', opencv_num_threads=0))\n",
            "img_root = 'archive/dataset/'\n",
            "load_from = 'C:\\\\Users\\\\omerf\\\\Desktop\\\\jet_detection_project\\\\work_dirs\\\\cascade_rcnn_r50_tiny\\\\best_coco_bbox_mAP_epoch_12.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        depth=50,\n",
            "        frozen_stages=1,\n",
            "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=True,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNet'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_size_divisor=32,\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "            2048,\n",
            "        ],\n",
            "        num_outs=5,\n",
            "        out_channels=256,\n",
            "        type='FPN'),\n",
            "    roi_head=dict(\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                        0.2,\n",
            "                        0.2,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=False),\n",
            "                num_classes=4,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.05,\n",
            "                        0.05,\n",
            "                        0.1,\n",
            "                        0.1,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=False),\n",
            "                num_classes=4,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "            dict(\n",
            "                bbox_coder=dict(\n",
            "                    target_means=[\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                        0.0,\n",
            "                    ],\n",
            "                    target_stds=[\n",
            "                        0.033,\n",
            "                        0.033,\n",
            "                        0.067,\n",
            "                        0.067,\n",
            "                    ],\n",
            "                    type='DeltaXYWHBBoxCoder'),\n",
            "                fc_out_channels=1024,\n",
            "                in_channels=256,\n",
            "                loss_bbox=dict(beta=1.0, type='SmoothL1Loss'),\n",
            "                loss_cls=dict(type='CrossEntropyLoss', use_sigmoid=False),\n",
            "                num_classes=4,\n",
            "                reg_class_agnostic=True,\n",
            "                roi_feat_size=7,\n",
            "                type='Shared2FCBBoxHead'),\n",
            "        ],\n",
            "        bbox_roi_extractor=dict(\n",
            "            featmap_strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            out_channels=256,\n",
            "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
            "            type='SingleRoIExtractor'),\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[\n",
            "            1.0,\n",
            "            0.8,\n",
            "            0.6,\n",
            "        ],\n",
            "        type='CascadeRoIHead'),\n",
            "    rpn_head=dict(\n",
            "        anchor_generator=dict(\n",
            "            ratios=[\n",
            "                0.5,\n",
            "                1.0,\n",
            "                2.0,\n",
            "            ],\n",
            "            scales=[\n",
            "                8,\n",
            "            ],\n",
            "            strides=[\n",
            "                4,\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "                64,\n",
            "            ],\n",
            "            type='AnchorGenerator'),\n",
            "        bbox_coder=dict(\n",
            "            target_means=[\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "                0.0,\n",
            "            ],\n",
            "            target_stds=[\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "                1.0,\n",
            "            ],\n",
            "            type='DeltaXYWHBBoxCoder'),\n",
            "        feat_channels=256,\n",
            "        in_channels=256,\n",
            "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
            "        type='RPNHead'),\n",
            "    test_cfg=dict(\n",
            "        rcnn=dict(\n",
            "            max_per_img=100,\n",
            "            nms=dict(iou_threshold=0.5, type='nms'),\n",
            "            score_thr=0.05),\n",
            "        rpn=dict(\n",
            "            max_per_img=1000,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=1000)),\n",
            "    train_cfg=dict(\n",
            "        rcnn=[\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    match_low_quality=False,\n",
            "                    min_pos_iou=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    pos_iou_thr=0.5,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    min_pos_iou=0.6,\n",
            "                    neg_iou_thr=0.6,\n",
            "                    pos_iou_thr=0.6,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "            dict(\n",
            "                assigner=dict(\n",
            "                    min_pos_iou=0.7,\n",
            "                    neg_iou_thr=0.7,\n",
            "                    pos_iou_thr=0.7,\n",
            "                    type='MaxIoUAssigner'),\n",
            "                pos_weight=-1,\n",
            "                sampler=dict(\n",
            "                    add_gt_as_proposals=True,\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    type='RandomSampler')),\n",
            "        ],\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                match_low_quality=True,\n",
            "                min_pos_iou=0.3,\n",
            "                neg_iou_thr=0.3,\n",
            "                pos_iou_thr=0.7,\n",
            "                type='MaxIoUAssigner'),\n",
            "            pos_weight=-1,\n",
            "            sampler=dict(\n",
            "                add_gt_as_proposals=False,\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                type='RandomSampler')),\n",
            "        rpn_proposal=dict(\n",
            "            max_per_img=1000,\n",
            "            min_bbox_size=0,\n",
            "            nms=dict(iou_threshold=0.7, type='nms'),\n",
            "            nms_pre=2000)),\n",
            "    type='CascadeRCNN')\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
            "    dict(by_epoch=True, gamma=0.1, milestones=[\n",
            "        8,\n",
            "        11,\n",
            "    ], type='MultiStepLR'),\n",
            "]\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file=\n",
            "        'C:\\\\Users\\\\omerf\\\\Desktop\\\\jet_detection_project\\\\coco_annotations\\\\instances_test.json',\n",
            "        data_prefix=dict(img='C:\\\\Users\\\\omerf\\\\Desktop\\\\archive\\\\dataset/'),\n",
            "        data_root='',\n",
            "        metainfo=dict(classes=(\n",
            "            'F16',\n",
            "            'F18',\n",
            "            'F22',\n",
            "            'F35',\n",
            "        )),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'C:\\\\Users\\\\omerf\\\\Desktop\\\\jet_detection_project\\\\coco_annotations\\\\instances_test.json',\n",
            "    metric='bbox',\n",
            "    type='CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackDetInputs'),\n",
            "]\n",
            "train_cfg = dict(max_epochs=24, type='EpochBasedTrainLoop', val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file=\n",
            "        'C:\\\\Users\\\\omerf\\\\Desktop\\\\jet_detection_project\\\\coco_annotations\\\\instances_train.json',\n",
            "        data_prefix=dict(img='C:\\\\Users\\\\omerf\\\\Desktop\\\\archive\\\\dataset/'),\n",
            "        data_root='',\n",
            "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
            "        metainfo=dict(classes=(\n",
            "            'F16',\n",
            "            'F18',\n",
            "            'F22',\n",
            "            'F35',\n",
            "        )),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(prob=0.5, type='RandomFlip'),\n",
            "            dict(type='PackDetInputs'),\n",
            "        ],\n",
            "        type='CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        1333,\n",
            "        800,\n",
            "    ), type='Resize'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PackDetInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file=\n",
            "        'C:\\\\Users\\\\omerf\\\\Desktop\\\\jet_detection_project\\\\coco_annotations\\\\instances_validation.json',\n",
            "        data_prefix=dict(img='C:\\\\Users\\\\omerf\\\\Desktop\\\\archive\\\\dataset/'),\n",
            "        data_root='',\n",
            "        metainfo=dict(classes=(\n",
            "            'F16',\n",
            "            'F18',\n",
            "            'F22',\n",
            "            'F35',\n",
            "        )),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                1333,\n",
            "                800,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'C:\\\\Users\\\\omerf\\\\Desktop\\\\jet_detection_project\\\\coco_annotations\\\\instances_validation.json',\n",
            "    metric='bbox',\n",
            "    type='CocoMetric')\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='DetLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = 'C:\\\\Users\\\\omerf\\\\Desktop\\\\jet_detection_project\\\\testing\\\\output_test\\\\nb_eval_val'\n",
            "\n",
            "12/22 13:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/22 13:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loads checkpoint by local backend from path: C:\\Users\\omerf\\Desktop\\jet_detection_project\\work_dirs\\cascade_rcnn_r50_tiny\\best_coco_bbox_mAP_epoch_12.pth\n",
            "12/22 13:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from C:\\Users\\omerf\\Desktop\\jet_detection_project\\work_dirs\\cascade_rcnn_r50_tiny\\best_coco_bbox_mAP_epoch_12.pth\n",
            "12/22 13:13:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)[0][ 50/570]    eta: 0:08:31  time: 0.9838  data_time: 0.1662  memory: 4899  \n",
            "12/22 13:13:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)[0][100/570]    eta: 0:04:52  time: 0.2608  data_time: 0.0010  memory: 4814  \n",
            "12/22 13:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)[0][150/570]    eta: 0:03:43  time: 0.3516  data_time: 0.0008  memory: 4820  \n",
            "12/22 13:14:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)[0][200/570]    eta: 0:02:46  time: 0.2000  data_time: 0.0009  memory: 4804  \n",
            "12/22 13:14:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)[0][250/570]    eta: 0:02:14  time: 0.3022  data_time: 0.0009  memory: 4810  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m runner \u001b[38;5;241m=\u001b[39m Runner\u001b[38;5;241m.\u001b[39mfrom_cfg(cfg)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SPLIT \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m SPLIT \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      7\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39mtest()\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmengine\\runner\\runner.py:1800\u001b[0m, in \u001b[0;36mRunner.val\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;66;03m# make sure checkpoint-related hooks are triggered after `before_run`\u001b[39;00m\n\u001b[0;32m   1798\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_or_resume()\n\u001b[1;32m-> 1800\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1801\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmengine\\runner\\loops.py:373\u001b[0m, in \u001b[0;36mValLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# compute metrics\u001b[39;00m\n\u001b[0;32m    376\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader\u001b[38;5;241m.\u001b[39mdataset))\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmengine\\runner\\loops.py:393\u001b[0m, in \u001b[0;36mValLoop.run_iter\u001b[1;34m(self, idx, data_batch)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;66;03m# outputs should be sequence of BaseDataElement\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16):\n\u001b[1;32m--> 393\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mprocess(data_samples\u001b[38;5;241m=\u001b[39moutputs, data_batch\u001b[38;5;241m=\u001b[39mdata_batch)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcall_hook(\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_val_iter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    397\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    398\u001b[0m     data_batch\u001b[38;5;241m=\u001b[39mdata_batch,\n\u001b[0;32m    399\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutputs)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmengine\\model\\base_model\\base_model.py:133\u001b[0m, in \u001b[0;36mBaseModel.val_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the predictions of given data.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03mCalls ``self.data_preprocessor(data, False)`` and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    list: The predictions of given data.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preprocessor(data, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmengine\\model\\base_model\\base_model.py:361\u001b[0m, in \u001b[0;36mBaseModel._run_forward\u001b[1;34m(self, data, mode)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Unpacks data for :meth:`forward`\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m    dict or list: Results of training or testing mode.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 361\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    363\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39mdata, mode\u001b[38;5;241m=\u001b[39mmode)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmdet\\models\\detectors\\base.py:94\u001b[0m, in \u001b[0;36mBaseDetector.forward\u001b[1;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(inputs, data_samples)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(inputs, data_samples)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmdet\\models\\detectors\\two_stage.py:227\u001b[0m, in \u001b[0;36mTwoStageDetector.predict\u001b[1;34m(self, batch_inputs, batch_data_samples, rescale)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict results from a batch of inputs and data samples with post-\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03mprocessing.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m        - masks (Tensor): Has a shape (num_instances, H, W).\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_bbox, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBbox head must be implemented.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 227\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# If there are no pre-defined proposals, use RPN to get proposals\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_data_samples[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmdet\\models\\detectors\\two_stage.py:110\u001b[0m, in \u001b[0;36mTwoStageDetector.extract_feat\u001b[1;34m(self, batch_inputs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_feat\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_inputs: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor]:\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract features.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m        different resolutions.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_neck:\n\u001b[0;32m    112\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck(x)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmdet\\models\\backbones\\resnet.py:643\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_layers):\n\u001b[0;32m    642\u001b[0m     res_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, layer_name)\n\u001b[1;32m--> 643\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mres_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_indices:\n\u001b[0;32m    645\u001b[0m         outs\u001b[38;5;241m.\u001b[39mappend(x)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmdet\\models\\backbones\\resnet.py:298\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    296\u001b[0m     out \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mcheckpoint(_inner_forward, x)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m_inner_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\mmdet\\models\\backbones\\resnet.py:269\u001b[0m, in \u001b[0;36mBottleneck.forward.<locals>._inner_forward\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    267\u001b[0m identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    268\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m--> 269\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_plugins:\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\omerf\\miniconda3\\envs\\jetdet\\lib\\site-packages\\torch\\nn\\functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# COCO Evaluation (en doğru ölçüm)- eğitim sırasında val yapılıyor zaten\n",
        "runner = Runner.from_cfg(cfg)\n",
        "\n",
        "if SPLIT == \"val\":\n",
        "    metrics = runner.val()\n",
        "elif SPLIT == \"test\":\n",
        "    metrics = runner.test()\n",
        "else:\n",
        "    raise ValueError(\"SPLIT 'val' veya 'test' olmalı\")\n",
        "\n",
        "metrics = metrics or {}\n",
        "print(\"Raw metrics keys:\", list(metrics.keys())[:20])\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393c1e1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metrikleri tabloya çevir (coco/*) göster\n",
        "coco_metrics = {k: v for k, v in metrics.items() if str(k).startswith(\"coco/\")}\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    [(k, float(v) if isinstance(v, (int, float, np.floating)) else v) for k, v in coco_metrics.items()],\n",
        "    columns=[\"metric\", \"value\"]\n",
        ").sort_values(\"metric\")\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc685878",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Öne çıkan metrikleri bar chart ile göster \n",
        "# (Matplotlib, tek grafik, renk belirtmeden)\n",
        "keys = [\n",
        "    \"coco/bbox_mAP\",\n",
        "    \"coco/bbox_mAP_50\",\n",
        "    \"coco/bbox_mAP_75\",\n",
        "    \"coco/bbox_mAP_s\",\n",
        "    \"coco/bbox_mAP_m\",\n",
        "    \"coco/bbox_mAP_l\",\n",
        "]\n",
        "vals = [coco_metrics.get(k, np.nan) for k in keys]\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(keys, vals)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(f\"COCO BBox Metrics ({SPLIT})\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d609e5",
      "metadata": {},
      "source": [
        "## Opsiyonel: Confusion Matrix + FP/FN Analizi\n",
        "Bu bölüm, **modeli tekrar inference** ettiği için daha yavaştır.\n",
        "- `RUN_CONFUSION=True` yaparsan çalışır.\n",
        "- `MAX_IMAGES` ile sınırlandırabilirsin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79ac7205",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion / FP / FN \n",
        "if not RUN_CONFUSION:\n",
        "    print(\"RUN_CONFUSION=False => Bu hücreyi geçiyoruz.\")\n",
        "else:\n",
        "    from pycocotools.coco import COCO\n",
        "    from mmdet.apis import init_detector, inference_detector\n",
        "\n",
        "    # split'e göre ann + img root\n",
        "    if SPLIT == \"val\":\n",
        "        ann_file = Path(cfg.val_dataloader.dataset.ann_file)\n",
        "        img_root = Path(cfg.val_dataloader.dataset.data_prefix.img)\n",
        "        classes = cfg.val_dataloader.dataset.metainfo[\"classes\"]\n",
        "    else:\n",
        "        ann_file = Path(cfg.test_dataloader.dataset.ann_file)\n",
        "        img_root = Path(cfg.test_dataloader.dataset.data_prefix.img)\n",
        "        classes = cfg.test_dataloader.dataset.metainfo[\"classes\"]\n",
        "\n",
        "    coco = COCO(str(ann_file))\n",
        "    img_ids = coco.getImgIds()\n",
        "    if MAX_IMAGES and MAX_IMAGES > 0:\n",
        "        img_ids = img_ids[:MAX_IMAGES]\n",
        "\n",
        "    ncls = len(classes)\n",
        "    conf = np.zeros((ncls, ncls), dtype=np.int64)\n",
        "    fp = np.zeros((ncls,), dtype=np.int64)\n",
        "    fn = np.zeros((ncls,), dtype=np.int64)\n",
        "\n",
        "    def coco_bbox_to_xyxy(b):\n",
        "        x, y, w, h = b\n",
        "        return np.array([x, y, x + w, y + h], dtype=np.float32)\n",
        "\n",
        "    def iou_xyxy(a, b):\n",
        "        x1 = max(a[0], b[0]); y1 = max(a[1], b[1])\n",
        "        x2 = min(a[2], b[2]); y2 = min(a[3], b[3])\n",
        "        iw = x2 - x1; ih = y2 - y1\n",
        "        if iw <= 0 or ih <= 0:\n",
        "            return 0.0\n",
        "        inter = iw * ih\n",
        "        area_a = (a[2]-a[0])*(a[3]-a[1])\n",
        "        area_b = (b[2]-b[0])*(b[3]-b[1])\n",
        "        union = area_a + area_b - inter\n",
        "        return float(inter/union) if union > 0 else 0.0\n",
        "\n",
        "    model = init_detector(cfg, str(CHECKPOINT_PATH), device=\"cuda\")\n",
        "\n",
        "    for img_id in img_ids:\n",
        "        img_info = coco.loadImgs([img_id])[0]\n",
        "        img_path = img_root / img_info[\"file_name\"]\n",
        "\n",
        "        ann_ids = coco.getAnnIds(imgIds=[img_id])\n",
        "        anns = coco.loadAnns(ann_ids)\n",
        "\n",
        "        gt_boxes = np.array([coco_bbox_to_xyxy(a[\"bbox\"]) for a in anns], dtype=np.float32) if anns else np.zeros((0,4), dtype=np.float32)\n",
        "        gt_labels = np.array([int(a[\"category_id\"])-1 for a in anns], dtype=np.int64) if anns else np.zeros((0,), dtype=np.int64)\n",
        "\n",
        "        result = inference_detector(model, str(img_path))\n",
        "\n",
        "        # Yeni MMDet: DetDataSample\n",
        "        if hasattr(result, \"pred_instances\"):\n",
        "            inst = result.pred_instances\n",
        "            b = inst.bboxes.detach().cpu().numpy()\n",
        "            l = inst.labels.detach().cpu().numpy()\n",
        "            s = inst.scores.detach().cpu().numpy()\n",
        "            keep = s >= SCORE_THR\n",
        "            pred_boxes = b[keep]\n",
        "            pred_labels = l[keep].astype(np.int64)\n",
        "        else:\n",
        "            # Eski format fallback (liste per class)\n",
        "            pred_boxes = []\n",
        "            pred_labels = []\n",
        "            for cls_id, arr in enumerate(result):\n",
        "                if arr is None or len(arr) == 0:\n",
        "                    continue\n",
        "                for row in arr:\n",
        "                    x1,y1,x2,y2,sc = row\n",
        "                    if sc >= SCORE_THR:\n",
        "                        pred_boxes.append([x1,y1,x2,y2])\n",
        "                        pred_labels.append(cls_id)\n",
        "            pred_boxes = np.array(pred_boxes, dtype=np.float32) if pred_boxes else np.zeros((0,4), dtype=np.float32)\n",
        "            pred_labels = np.array(pred_labels, dtype=np.int64) if pred_labels else np.zeros((0,), dtype=np.int64)\n",
        "\n",
        "        used_gt = set()\n",
        "\n",
        "        # class-agnostic matching -> confusion\n",
        "        for i in range(len(pred_boxes)):\n",
        "            pb = pred_boxes[i]\n",
        "            pl = int(pred_labels[i])\n",
        "\n",
        "            best_iou = 0.0\n",
        "            best_j = -1\n",
        "            for j in range(len(gt_boxes)):\n",
        "                if j in used_gt:\n",
        "                    continue\n",
        "                iou = iou_xyxy(pb, gt_boxes[j])\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_j = j\n",
        "\n",
        "            if best_j >= 0 and best_iou >= IOU_THR:\n",
        "                tl = int(gt_labels[best_j])\n",
        "                conf[tl, pl] += 1\n",
        "                used_gt.add(best_j)\n",
        "            else:\n",
        "                fp[pl] += 1\n",
        "\n",
        "        for j in range(len(gt_boxes)):\n",
        "            if j not in used_gt:\n",
        "                fn[int(gt_labels[j])] += 1\n",
        "\n",
        "    print(\"Confusion matrix computed.\")\n",
        "\n",
        "    # Plot confusion\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.imshow(conf, interpolation=\"nearest\")\n",
        "    plt.title(f\"Confusion Matrix ({SPLIT}) IoU>={IOU_THR} score>={SCORE_THR}\")\n",
        "    plt.colorbar()\n",
        "    tick = np.arange(ncls)\n",
        "    plt.xticks(tick, classes, rotation=45, ha=\"right\")\n",
        "    plt.yticks(tick, classes)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "\n",
        "    for i in range(ncls):\n",
        "        for j in range(ncls):\n",
        "            plt.text(j, i, str(conf[i, j]), ha=\"center\", va=\"center\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # FP/FN table\n",
        "    df_err = pd.DataFrame({\n",
        "        \"class\": list(classes),\n",
        "        \"FP\": fp.astype(int),\n",
        "        \"FN\": fn.astype(int),\n",
        "    })\n",
        "    df_err\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jetdet",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
